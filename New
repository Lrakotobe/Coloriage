import org.apache.spark.sql.Column;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.types.DecimalType;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;

import static org.apache.spark.sql.functions.*;

public class DecimalUtils {

    public static Dataset<Row> ensureDecimalsDoNotConvertToSciNotation(Dataset<Row> df) {
        // Obtenir le schéma du DataFrame
        StructType schema = df.schema();

        // Créer une liste de colonnes modifiées
        Column[] columns = new Column[df.columns().length];
        
        for (int i = 0; i < df.columns().length; i++) {
            String column = df.columns()[i];
            StructField field = schema.apply(column);
            
            // Vérifier si le type de la colonne est Decimal
            if (field.dataType() instanceof DecimalType) {
                DecimalType decimalType = (DecimalType) field.dataType();
                int scale = decimalType.scale();
                
                // Si l'échelle est 6 ou plus, formater le nombre avec 'format_number'
                if (scale >= 6) {
                    columns[i] = format_number(col(column), scale).alias(column);
                } else {
                    columns[i] = col(column);
                }
            } else {
                // Si ce n'est pas un Decimal, laisser la colonne telle quelle
                columns[i] = col(column);
            }
        }

        // Sélectionner les colonnes avec ou sans formatage
        return df.select(columns);
    }
}
